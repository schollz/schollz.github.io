<!doctype html><html lang=en><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Zack&#39;s Notablog | Using crawdad</title><meta name=description content><meta name=image content><meta itemprop=name content="Using crawdad"><meta itemprop=description content><meta itemprop=image content><meta name=twitter:card content=summary><meta name=twitter:title content="Using crawdad"><meta name=twitter:description content><meta name=twitter:site content=@yakczar><meta name=twitter:creator content=@yakczar><meta name=twitter:image:src content><meta name=og:title content="Using crawdad"><meta name=og:description content><meta name=og:url content=/crawdad/><meta name=og:site_name content="Using crawdad"><meta name=og:type content=article><meta name=article:author content=yakczar><meta name=article:tag content=coding><link rel=stylesheet href=/css/style4.css><script src=/js/caption.js></script><link rel=icon type=image/png href=/img/favicon/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/img/favicon/favicon-16x16.png sizes=16x16><script>function getJSON(url){var script=document.createElement('script');script.setAttribute('src',url);script.setAttribute('type','text/javascript');document.getElementsByTagName('head')[0].appendChild(script);}
function cbfunc(data1){console.log(data1);var quoteP=document.getElementById("quoteP");quoteP.innerHTML="<em>“"+data1.text+"” - "+data1.name+"</em>";}
getJSON("https:\/\/randomquote.schollz.com?callback=cbfunc")</script><img src="https://analytics.schollz.com/1.png?page=%2fcrawdad%2f" width=1px height=1px style=float:right><div id=header><div class=left></div><div class=right></div></div><div id=loadingMask style=width:100%;height:100%;position:fixed;background:#fff></div><script>function fadeOut(el){el.style.opacity=1;var last=+new Date();var tick=function(){el.style.opacity=+el.style.opacity-(new Date()-last)/80;last=+new Date();if(el.style.opacity>0){(window.requestAnimationFrame&&requestAnimationFrame(tick))||setTimeout(tick,16);}else{el.style.display='none';}};tick();}
function ready(fn){if(document.attachEvent?document.readyState==="complete":document.readyState!=="loading"){el=document.getElementById('loadingMask');fadeOut(el);var elements=document.querySelectorAll("img");Array.prototype.forEach.call(elements,function(el,i){if(el.getAttribute("alt")){const caption=document.createElement('figcaption');var node=document.createTextNode(el.getAttribute("alt"));caption.appendChild(node);const wrapper=document.createElement('figure');wrapper.className='image';el.parentNode.insertBefore(wrapper,el);el.parentNode.removeChild(el);wrapper.appendChild(el);wrapper.appendChild(caption);}});}else{document.addEventListener('DOMContentLoaded',fn);}
guestbook.innerHTML="Loading ...";var tag=document.createElement("script");var message=encodeURIComponent(document.querySelector('#message').value);var name=encodeURIComponent(document.querySelector('#name').value);var email=encodeURIComponent(document.querySelector('#email').value);tag.src=`${serverURL}/jsonp?callback=myCallback&message=${message}&name=${name}&email=${name}`;document.querySelector("head").appendChild(tag);}
document.onreadystatechange=ready;</script><div id=documentbody><div class=wtblog><div class=maintext><div class="wikitext titlehack"><h1>Using crawdad</h1><div class=posttitle><small>October 11, 2017</small></div></div><div class=wikitext><p><img src=https://user-images.githubusercontent.com/6550035/31456157-58663efe-ae76-11e7-8e53-6a2a5b7a196c.png alt="A new, simple, powerful content extractor"><p><em>crawdad</em> is a simple, yet powerful alternative for scraping in a distributed, persistent manner (backed by Redis). It can do simple things, like generating site maps. It can also do complicated things, like extracting all the quotes from every page on a quotes website (tutorial follows).<h2 id=install>Install</h2><p>First <a href=https://www.docker.com/community-edition>get Docker</a> which will be used for running Redis.<p>Then you can simply download <em>crawdad</em>:<div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh>$ wget https://github.com/schollz/crawdad/releases/download/v3.0.0/crawdad_3.0.0_linux_amd64.zip
$ unzip crawdad*zip
$ sudo mv crawdad*amd64 /usr/local/bin/crawdad</code></pre></div><p>Unlike many other scraping frameworks, <em>crawdad</em> is a single binary that has no dependencies.<h2 id=configure>Configure</h2><p>For scraping, <em>crawdad</em> requires creating a <a href=https://github.com/schollz/pluck#use-config-file>pluck configuration file</a>. Here is the configuration file for scraping <a href=http://quotes.toscrape.com>quotes.toscrape.com</a>:</p><script src=https://gist.github.com/schollz/02205b5c1a3c5ade132e17ce61ce1213.js></script><p><em>pluck</em> is a language-agnostic way of extracting structured data from text without HTML/CSS/Regex. Essentially <em>pluck</em> is configured in a way you would tell your friend to grab data.<p>For example, the first <em>pluck</em> unit describes how you would get the quote text from <a href=http://quotes.toscrape.com>quotes.toscrape.com</a>. Starting from the beginning of the source, you look for the string &ldquo;<code>span class=&quot;text&quot;</code>&rdquo; (called an <em>activator</em>). Once that is found, you look for a &ldquo;<code>&gt;</code>&rdquo;, the next activator. Then you capture all the characters until a &ldquo;<code>&lt;</code>&rdquo; is seen (the <em>deactivator</em>). This will allow you to collect all the quotes.<p>Each of the <em>pluck</em> units will be found simultaneously and extracted from any HTML page crawled by <em>crawdad</em>.<h2 id=run>Run</h2><p>First, start Redis with Docker:<div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh>$ docker run -d -p <span style=color:#ae81ff>6374</span>:6379 redis</code></pre></div><p>and then start <em>crawdad</em>:<pre><code>$ time crawdad -p 6374 -set -u http://quotes.toscrape.com -pluck quotes.toml -include '/page/' -exclude '/tag/'
0.12s user 0.03s system 5% cpu 2.666 total
</code></pre><p>The <code>-set</code> flag tells the <em>crawdad</em> to create some new settings with a URL (<code>-u</code>) and a <em>pluck</em> configuration (<code>-pluck</code>) and with some inclusions/exclusions (<code>-include</code>/<code>-exclude</code>). The inclusions and exclusions ensures that only the <code>/page</code> links will be followed (in order to compare with scrapy).<h2 id=extract-data>Extract data</h2><p>The data from <em>crawdad</em> can be parsed in the same as <em>scrapy</em> by first dumping it,<pre><code>$ crawdad -p 6374 -done done.json
</code></pre><p>The data, <code>done.json</code>, contains each URL as a key and the data it extracted. It needs to be quickly parsed, too, which can be done lickity-split in Python in 12 lines of code:</p><script src=https://gist.github.com/schollz/f27547bb4716fc14fd574e9bbdad57a1.js></script><h2 id=crawdad-bonuses><em>crawdad</em> bonuses</h2><p><em>crawdad</em> has some other mighty benefits as well. Once initiated, you can run another crawdad on a different machine:<div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh>$ crawdad -p <span style=color:#ae81ff>6374</span> -s X.X.X.X</code></pre></div><p>This will start crawling using the same parameters as the first <em>crawdad</em>, but will pull from the queue. Thus, you can easily make a distributed crawler.<p>Also, since it is backed by Redis, <em>crawdad</em> is resilient to interruptions and allows you to restart from the point that it was interrupted. Try it!<h1 id=comparison-with-scrapy>Comparison with <em>scrapy</em></h1><p>Here I will compare scraping the same site, <a href=http://quotes.toscrape.com/>quotes.toscrape.com</a> with <em>crawdad</em> (my creation) and <em>scrapy</em> (the popular framework for scraping).<p><img src=https://user-images.githubusercontent.com/6550035/31486741-b06865e4-aef5-11e7-8b0d-c5ed107b25b4.png alt="scrapy is really useful tool to get started in scraping."><p><em>scrapy</em> is powerful, but complicated. Lets follow the tutorial to get a baseline on how a scrapy should run.<h2 id=install-1>Install</h2><p>First install <em>scrapy</em> by installing the dependencies (there are a lot of dependencies).<div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh>$ sudo apt-get install python-dev python-pip libxml2-dev libxslt1-dev zlib1g-dev libffi-dev libssl-dev
$ sudo -H python3 -m pip install --upgrade scrapy</code></pre></div><p>Once you get it install you can check the version:<div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh>$ scrapy -version
Scrapy <span style=color:#ae81ff>1</span>.4.0 - project: quotesbot</code></pre></div><h2 id=configure-1>Configure</h2><p>Actually, I will just use the <a href=https://github.com/scrapy/quotesbot>tutorial of <em>scrapy</em></a> to skip building it myself.<div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh>$ git clone https://github.com/scrapy/quotesbot.git
$ cd quotesbot</code></pre></div><p><em>scrapy</em> is not simple. It requires &gt; 40 lines of Python code in several different files (<code>items.py</code>, <code>pipelines.py</code>, <code>settings.py</code>, <code>spiders/toscrape-css.py</code>).<h2 id=run-1>Run</h2><p>Lets run and time the result:<pre><code>$ time scrapy crawl toscrape-xpath -o quotes.json
1.06s user 0.08s system 29% cpu 3.877 total
</code></pre><p><em>scrapy</em> is about 10-30% slower than <em>crawdad</em>, plus it can not easily be run in a distributed, persistent way.</div><br><div class=collapse tabindex=1><a id=commenttoggle href=#commentssection onclick="toggle_visibility('commentssection');">Show comments <span id=commentsnum></span></a><script>function toggle_visibility(id){var e=document.getElementById(id);if(e.style.display=='block'){e.style.display='none';document.getElementById("commenttoggle").innerText="Show comments";}else{e.style.display='block';document.getElementById("commenttoggle").innerText="Hide comments";}}</script><div id=commentssection style=display:none><hr><div id=comments></div><div class=guestbook-form><strong>Leave a comment:</strong>
<textarea rows=5 cols=75 id=message name=message class=guestbook></textarea><br><table style=margin-bottom:0><tr><td style=padding-right:10px><label for=name>Who are you?</label><td><input id=name class=guestbook size=40><tr><td style=padding-right:10px><label for=whourl>(optional URL)</label><td><input id=email class=guestbook size=40 type=url><tr><td><input class=guestbook-button type=button id=btn value=Submit></table></div><script>var serverURL="https:\/\/guestbook.schollz.com"
var btn=document.getElementById("btn");var guestbook=document.getElementById("comments");var firstMessage=0;function myCallback(acptlang){if(acptlang.Message!=""&&firstMessage==1){alert(acptlang.Message);firstMessage=1;}
guestbook.innerHTML="";if(acptlang.Entries.length>0){var commentsNum=document.getElementById("commentsnum");commentsNum.innerText="("+acptlang.Entries.length+")"}
for(var i=0;i<acptlang.Entries.length;i++){guestbook.innerHTML=guestbook.innerHTML+
`<div class="comment">
    <div class="entryid"> By ${acptlang.Entries[i].Name} on ${acptlang.Entries[i].DateString} in ${acptlang.Entries[i].Location}: </div>
    <blockquote> <div class="wikitext">${acptlang.Entries[i].Message}
    </div> </blockquote> </div>`}}
function jsonp(){guestbook.innerHTML="Loading ...";var tag=document.createElement("script");var message=encodeURIComponent(document.querySelector('#message').value);var name=encodeURIComponent(document.querySelector('#name').value);var email=encodeURIComponent(document.querySelector('#email').value);tag.src=`${serverURL}/jsonp?callback=myCallback&message=${message}&name=${name}&email=${name}`;document.querySelector("head").appendChild(tag);}
btn.addEventListener("click",jsonp);</script></div><br></div><small>Written on <a href=/written/2017-10-11>11</a>
<a href=/written/2017-10>October</a>
<a href=/written/2017>2017</a>.
Categories:
<a href=/tags/coding/>coding</a>.</small><br><br><table border=0 width=100%><tr><td width=50% style=padding-right:.5em><table><tr><td>&laquo;<td><a href=/docker-news/>Read news in the terminal with Docker</a>&nbsp;</table><td width=50% style="padding-left:.5em;border-left:1px dotted"><table><tr><td><a href=/sentences/ style=float:right>Most sentences are unique</a><td>&raquo;</table></table></div><div class=sidebar><div class=readme><div class=wikitext><p><a href=/>Full index of entries</a><p>Subjects:
<a href=/tags/bitcoin>bitcoin</a>&nbsp;
<a href=/tags/books>books</a>&nbsp;
<a href=/tags/brain>brain</a>&nbsp;
<a href=/tags/coding>coding</a>&nbsp;
<a href=/tags/food>food</a>&nbsp;
<a href=/tags/golang>golang</a>&nbsp;
<a href=/tags/language>language</a>&nbsp;
<a href=/tags/open-source>open-source</a>&nbsp;
<a href=/tags/painting>painting</a>&nbsp;
<a href=/tags/protein-folding>protein-folding</a>&nbsp;
<a href=/tags/running>running</a>&nbsp;
<a href=/tags/science>science</a>&nbsp;
<a href=/tags/thoughts>thoughts</a>&nbsp;
<a href=/tags/tools>tools</a>&nbsp;<p>Github:
<a href=https://github.com/schollz>@schollz</a><p>Twitter:
<a href=https://twitter.com/yakczar>@yakczar</a><p align=center>* * *<p id=quoteP><div class=sidesearch style=font-size:small><form onsubmit="location.href='/search/?s='+document.getElementById('myInput').value;return false;">Search:
<input id=myInput size=15></form></div><p><a href=/about>About</a>&nbsp;&middot;&nbsp;<a href=/index.xml>RSS feed</a></div></div></div></div></div>