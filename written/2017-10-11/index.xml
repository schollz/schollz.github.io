<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>2017 10 11 on Zack&#39;s Notablog</title><link>/written/2017-10-11/</link><description>Recent content in 2017 10 11 on Zack&#39;s Notablog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 11 Oct 2017 20:03:10 -0600</lastBuildDate><atom:link href="/written/2017-10-11/index.xml" rel="self" type="application/rss+xml"/><item><title>Using crawdad</title><link>/crawdad/</link><pubDate>Wed, 11 Oct 2017 20:03:10 -0600</pubDate><guid>/crawdad/</guid><description>crawdad is a simple, yet powerful alternative for scraping in a distributed, persistent manner (backed by Redis). It can do simple things, like generating site maps. It can also do complicated things, like extracting all the quotes from every page on a quotes website (tutorial follows).
Install First get Docker which will be used for running Redis.
Then you can simply download crawdad:
$ wget https://github.com/schollz/crawdad/releases/download/v3.0.0/crawdad_3.0.0_linux_amd64.zip $ unzip crawdad*zip $ sudo mv crawdad*amd64 /usr/local/bin/crawdad Unlike many other scraping frameworks, crawdad is a single binary that has no dependencies.</description></item></channel></rss>